version: '3'
services:
  # MICROSERVICES

  # basket-api:
  #   container_name: basket-api
  #   image: basket-api
  #   build:
  #     context: src/baskets/Basket.Api
  #   ports:
  #     - 8081:80
  #   depends_on:
  #     - redis
  #     - elasticsearch
  #     - apm-server

  # orders-api:
  #   container_name: orders-api
  #   image: orders-api
  #   build:
  #     context: src/orders/Orders.Api
  #   environment:
  #     - KAFKA__BOOTSTRAPSERVERS=kafka:29092
  #   ports:
  #     - 8082:80
  #   depends_on:
  #     - mongo
  #     - kafka-setup
  #     - elasticsearch
  #     - apm-server

  # orders-consumer:
  #   container_name: orders-consumer
  #   image: orders-consumer
  #   build:
  #     context: src/orders/Orders.Consumer
  #   environment:
  #     - KAFKA__BOOTSTRAPSERVERS=kafka:29092
  #   depends_on:
  #     - mongo
  #     - zookeeper
  #     - kafka
  #     - kafka-setup
  #     - elasticsearch
  #     - apm-server
  #   restart: on-failure

  # products-api:
  #   container_name: products-api
  #   image: products-api
  #   build:
  #     context: src/products/Products.Api
  #   ports:
  #     - 8083:80
  #   depends_on:
  #     - mssql
  #     - elasticsearch
  #     - apm-server

  # users-idp:
  #   container_name: users-idp
  #   image: users-idp
  #   build:
  #     context: src/users/users.Idp
  #   ports:
  #     - 8084:80
  #   depends_on:
  #     - postgres
  #     - elasticsearch
  #     - apm-server

  # MONITORING SERVICES

  apm-server:
    container_name: apm-server
    image: docker.elastic.co/apm/apm-server:7.16.2
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    cap_add: ['CHOWN', 'DAC_OVERRIDE', 'SETGID', 'SETUID']
    cap_drop: ['ALL']
    ports:
      - 8200:8200
    command: >
      apm-server -e
        -E apm-server.rum.enabled=true
        -E setup.kibana.host=kibana:5601
        -E setup.template.settings.index.number_of_replicas=0
        -E apm-server.kibana.enabled=true
        -E apm-server.kibana.host=kibana:5601
        -E output.elasticsearch.hosts=["elasticsearch:9200"]
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2
    environment:
      - bootstrap.memory_lock=true
      - cluster.name=docker-cluster
      - cluster.routing.allocation.disk.threshold_enabled=false
      - discovery.type=single-node
      - ES_JAVA_OPTS=-XX:UseAVX=2 -Xms1g -Xmx1g
    ulimits:
      memlock:
        hard: -1
        soft: -1
    ports:
      - 9200:9200
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:7.16.2
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - 5601:5601
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status

  # DATABASES

  postgres:
    container_name: postgres
    image: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      PGDATA: /data/postgres
    ports:
      - 5432:5432

  mssql:
    image: 'mcr.microsoft.com/mssql/server'
    container_name: mssql
    environment:
      SA_PASSWORD: 'Dev@123456'
      ACCEPT_EULA: 'Y'
    ports:
      - 1433:1433

  mongo:
    image: mongo
    container_name: mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: mongo
      MONGO_INITDB_ROOT_PASSWORD: mongo
    ports:
      - 27017:27017

  redis:
    image: redis
    container_name: redis
    command: redis-server --requirepass redis --appendonly yes
    hostname: redis
    ports:
      - 6379:6379

  # MESSAGE BROKER

  # zookeeper:
  #   image: confluentinc/cp-zookeeper:latest
  #   container_name: zookeeper
  #   ports:
  #     - 2181:2181
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181

  # kafka:
  #   image: confluentinc/cp-kafka:latest
  #   container_name: kafka
  #   depends_on:
  #     - zookeeper
  #   ports:
  #     - 9092:9092
  #   expose:
  #     - 29092
  #   environment:
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_MIN_INSYNC_REPLICAS: 1

  # kafka-setup:
  #   image: confluentinc/cp-kafka:latest
  #   container_name: kafka-setup
  #   depends_on:
  #     - kafka
  #   entrypoint: ['/bin/sh', '-c']
  #   command: |
  #     "
  #     # blocks until kafka is reachable
  #     kafka-topics --bootstrap-server kafka:29092 --list

  #     echo -e 'Creating kafka topics'
  #     kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic order-created-topic --replication-factor 1 --partitions 3

  #     echo -e 'Successfully created the following topics:'
  #     kafka-topics --bootstrap-server kafka:29092 --list
  #     "

  # kafdrop:
  #   image: obsidiandynamics/kafdrop:latest
  #   container_name: kafdrop
  #   depends_on:
  #     - kafka
  #   ports:
  #     - 9000:9000
  #   environment:
  #     KAFKA_BROKERCONNECT: kafka:29092
